# -*- coding: utf-8 -*-
"""stIndexPY_v0.1.g

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RQtT8xGY_DIGrvXczqvcdRtKAZo0_k00
"""

# -*- coding: utf-8 -*-
"""
Gerenciador Aprimorado do Banco de Dados de Acidentes de Trânsito com Compressão, Criptografia e Índice B-Tree

Este script mescla o backend de stCRUDDataObjectPY_v4epsilon.py com o frontend
de stCRUDDataObjectPY_v3alpha.py, adicionando interfaces para:
- Compressão/descompressão LZW/Huffman dos arquivos de banco de dados e índice.
- Criptografia/descriptografia híbrida AES/RSA dos arquivos de banco de dados e índice.
- Índice B-Tree para gerenciamento eficiente de registros (substitui o índice de dicionário simples).
"""

import streamlit as st
import csv
import os
import struct
import json
import hashlib
import time
import filelock
import logging
from datetime import datetime, date
from pathlib import Path
from typing import List, Dict, Optional, Union, Callable, Any, Iterator, Tuple
import shutil
import tempfile
import traceback
import math
from collections import OrderedDict, Counter, defaultdict, deque
import heapq
import io
import re
import getpass  # Importa para entrada de senha (usado em operações de criptografia)

# --- Importações de Criptografia de pycryptonew.py ---
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.primitives import serialization, hashes
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.backends import default_backend

# --- Constantes de Configuração (Centralizadas - de v4epsilon) ---
APP_CONFIG = {
    "DB_DIR": Path.home() / 'Documents' / 'Data',  # Usando Pathlib
    "DB_FILE_NAME": 'traffic_accidents.db',
    "INDEX_FILE_NAME": 'traffic_accidents.idx',
    "BTREE_INDEX_FILE_NAME": 'traffic_accidents_btree.idx',  # Novo arquivo de índice B-Tree
    "ID_COUNTER_FILE_NAME": 'id_counter.txt',
    "LOCK_FILE_NAME": 'db.lock',
    "RSA_KEYS_DIR": Path.home() / 'Documents' / 'RSA_Keys',  # Usando Pathlib
    "LOG_FILE_NAME": 'app_activity.log',
    "BTREE_PAGE_SIZE": 4096,  # Tamanho da página 4KB
    "BTREE_MIN_DEGREE": 31  # Grau mínimo (t) para B-Tree
}

# --- Caminhos Globais ---
DB_FILE_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["DB_FILE_NAME"]
INDEX_FILE_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["INDEX_FILE_NAME"]
BTREE_INDEX_FILE_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["BTREE_INDEX_FILE_NAME"]
ID_COUNTER_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["ID_COUNTER_FILE_NAME"]
LOCK_FILE_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["LOCK_FILE_NAME"]
RSA_PUBLIC_KEY_PATH = APP_CONFIG["RSA_KEYS_DIR"] / 'public_key.pem'
RSA_PRIVATE_KEY_PATH = APP_CONFIG["RSA_KEYS_DIR"] / 'private_key.pem'
LOG_FILE_PATH = APP_CONFIG["DB_DIR"] / APP_CONFIG["LOG_FILE_NAME"]

BACKUP_PATH = APP_CONFIG["DB_DIR"] / 'backup' # Subdiretório para backups
HUFFMAN_FOLDER = APP_CONFIG["DB_DIR"] / 'huffman_compressed'
LZW_FOLDER = APP_CONFIG["DB_DIR"] / 'lzw_compressed'

# --- Configurar logging ---
# Centralizar a configuração de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE_PATH),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Inicializa variáveis de estado da sessão Streamlit
if 'db' not in st.session_state:
    st.session_state.db = None # Será inicializado com DBManager ou BTreeDBManager
if 'db_type' not in st.session_state:
    st.session_state.db_type = "default" # "default" ou "btree"
if 'logger' not in st.session_state:
    st.session_state.logger = logger
if 'rsa_keys_generated' not in st.session_state:
    st.session_state.rsa_keys_generated = False
if 'key_pair' not in st.session_state:
    st.session_state.key_pair = {"public": None, "private": None}


# --- Classe DataObject (Refatorada para corresponder ao DataObject Java) ---
class DataObject:
    """
    Representa um único registro de acidente de trânsito, espelhando a estrutura do DataObject Java.
    Inclui lógica de validação e conversão para entradas do Streamlit.
    """
    def __init__(self, data: Dict[str, Any]):
        self._data = self._validate_and_clean_data(data)

    def _validate_and_clean_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Valida e limpa os dados de entrada, aplicando tipos e restrições
        baseados nos atributos do DataObject Java.
        """
        cleaned_data = {}
        # Define campos esperados e sua lógica de validação/conversão
        # Mapeado dos atributos do DataObject Java
        fields = {
            "id_registro": (int, lambda x: int(x) if x is not None and str(x).isdigit() else 0),
            "crash_date": (str, lambda x: str(x).strip() if x is not None else ""), # String de timestamp completa
            "data_local": (str, lambda x: str(x).strip() if x is not None else ""), # LocalDate em Java, string 'YYYY-MM-DD' em Python
            "traffic_control_device": (str, lambda x: str(x).strip() if x is not None else ""),
            "weather_condition": (str, lambda x: str(x).strip() if x is not None else ""),
            "lighting_condition": (list, lambda x: [s.strip() for s in str(x).split(',') if s.strip()] if x is not None else []),
            "first_crash_type": (str, lambda x: str(x).strip() if x is not None else ""),
            "trafficway_type": (str, lambda x: str(x).strip() if x is not None else ""),
            "alignment": (str, lambda x: str(x).strip() if x is not None else ""),
            "roadway_surface_cond": (str, lambda x: str(x).strip() if x is not None else ""),
            "road_defect": (str, lambda x: str(x).strip() if x is not None else ""),
            "crash_type": (list, lambda x: [s.strip() for s in str(x).split(',') if s.strip()] if x is not None else []),
            "intersection_related_i": (bool, lambda x: bool(x)), # Campo booleano
            "damage": (str, lambda x: str(x).strip() if x is not None else ""),
            "prim_contributory_cause": (str, lambda x: str(x).strip() if x is not None else ""),
            "num_units": (int, lambda x: int(x) if x is not None and str(x).isdigit() else 0),
            "most_severe_injury": (list, lambda x: [s.strip() for s in str(x).split(',') if s.strip()] if x is not None else []),
            "injuries_total": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "injuries_fatal": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "injuries_incapacitating": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "injuries_non_incapacitating": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "injuries_reported_not_evident": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "injuries_no_indication": (float, lambda x: float(x) if (isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else 0.0),
            "crash_hour": (int, lambda x: int(x) if x is not None and str(x).isdigit() else 0),
            "crash_day_of_week": (int, lambda x: int(x) if x is not None and str(x).isdigit() else 0),
            "crash_month": (int, lambda x: int(x) if x is not None and str(x).isdigit() else 0),
        }

        for field, (expected_type, converter) in fields.items():
            value = data.get(field)
            try:
                converted_value = converter(value)
                # Validações específicas (podem ser estendidas)
                if field in ["injuries_total", "injuries_fatal", "injuries_incapacitating",
                             "injuries_non_incapacitating", "injuries_reported_not_evident",
                             "injuries_no_indication", "num_units"] and converted_value < 0:
                    raise ValueError(f"'{field}' não pode ser negativo.")

                cleaned_data[field] = converted_value
            except (ValueError, TypeError) as e:
                st.session_state.logger.warning(f"Erro de validação para o campo '{field}' com valor '{value}': {e}. Usando valor padrão/ignorado.")
                if expected_type == str:
                    cleaned_data[field] = ""
                elif expected_type == int:
                    cleaned_data[field] = 0
                elif expected_type == float:
                    cleaned_data[field] = 0.0
                elif expected_type == list:
                    cleaned_data[field] = []
                elif expected_type == bool:
                    cleaned_data[field] = False
                else:
                    cleaned_data[field] = None

        # Garante que 'id_registro' seja um inteiro, para novos registros será 0
        if cleaned_data.get("id_registro") is None:
            cleaned_data["id_registro"] = 0

        return cleaned_data

    def to_dict(self) -> Dict[str, Any]:
        """Retorna os dados como um dicionário."""
        return self._data

    def to_csv_row(self) -> Dict[str, Any]:
        """Retorna os dados como um dicionário adequado para escrita em CSV."""
        # Converte listas de volta para strings separadas por vírgula para CSV
        csv_data = self._data.copy()
        for key in ["lighting_condition", "crash_type", "most_severe_injury"]:
            if isinstance(csv_data.get(key), list):
                csv_data[key] = " , ".join(csv_data[key])
        if "intersection_related_i" in csv_data:
            csv_data["intersection_related_i"] = "S" if csv_data["intersection_related_i"] else "N"
        return csv_data

    # Propriedades para cada atributo, espelhando getters/setters do Java para facilidade de acesso
    @property
    def id_registro(self) -> int:
        return self._data.get("id_registro")

    @id_registro.setter
    def id_registro(self, value: int):
        self._data["id_registro"] = value

    @property
    def crash_date(self) -> str:
        return self._data.get("crash_date")

    @crash_date.setter
    def crash_date(self, value: str):
        self._data["crash_date"] = value

    @property
    def data_local(self) -> str: # Armazenado como string, mas originalmente LocalDate em Java
        return self._data.get("data_local")

    @data_local.setter
    def data_local(self, value: str):
        self._data["data_local"] = value

    @property
    def traffic_control_device(self) -> str:
        return self._data.get("traffic_control_device")

    @traffic_control_device.setter
    def traffic_control_device(self, value: str):
        self._data["traffic_control_device"] = value

    @property
    def weather_condition(self) -> str:
        return self._data.get("weather_condition")

    @weather_condition.setter
    def weather_condition(self, value: str):
        self._data["weather_condition"] = value

    @property
    def lighting_condition(self) -> List[str]:
        return self._data.get("lighting_condition")

    @lighting_condition.setter
    def lighting_condition(self, value: List[str]):
        self._data["lighting_condition"] = value

    @property
    def first_crash_type(self) -> str:
        return self._data.get("first_crash_type")

    @first_crash_type.setter
    def first_crash_type(self, value: str):
        self._data["first_crash_type"] = value

    @property
    def trafficway_type(self) -> str:
        return self._data.get("trafficway_type")

    @trafficway_type.setter
    def trafficway_type(self, value: str):
        self._data["trafficway_type"] = value

    @property
    def alignment(self) -> str:
        return self._data.get("alignment")

    @alignment.setter
    def alignment(self, value: str):
        self._data["alignment"] = value

    @property
    def roadway_surface_cond(self) -> str:
        return self._data.get("roadway_surface_cond")

    @roadway_surface_cond.setter
    def roadway_surface_cond(self, value: str):
        self._data["roadway_surface_cond"] = value

    @property
    def road_defect(self) -> str:
        return self._data.get("road_defect")

    @road_defect.setter
    def road_defect(self, value: str):
        self._data["road_defect"] = value

    @property
    def crash_type(self) -> List[str]:
        return self._data.get("crash_type")

    @crash_type.setter
    def crash_type(self, value: List[str]):
        self._data["crash_type"] = value

    @property
    def intersection_related_i(self) -> bool:
        return self._data.get("intersection_related_i")

    @intersection_related_i.setter
    def intersection_related_i(self, value: bool):
        self._data["intersection_related_i"] = value

    @property
    def damage(self) -> str:
        return self._data.get("damage")

    @damage.setter
    def damage(self, value: str):
        self._data["damage"] = value

    @property
    def prim_contributory_cause(self) -> str:
        return self._data.get("prim_contributory_cause")

    @prim_contributory_cause.setter
    def prim_contributory_cause(self, value: str):
        self._data["prim_contributory_cause"] = value

    @property
    def num_units(self) -> int:
        return self._data.get("num_units")

    @num_units.setter
    def num_units(self, value: int):
        self._data["num_units"] = value

    @property
    def most_severe_injury(self) -> List[str]:
        return self._data.get("most_severe_injury")

    @most_severe_injury.setter
    def most_severe_injury(self, value: List[str]):
        self._data["most_severe_injury"] = value

    @property
    def injuries_total(self) -> float:
        return self._data.get("injuries_total")

    @injuries_total.setter
    def injuries_total(self, value: float):
        self._data["injuries_total"] = value

    @property
    def injuries_fatal(self) -> float:
        return self._data.get("injuries_fatal")

    @injuries_fatal.setter
    def injuries_fatal(self, value: float):
        self._data["injuries_fatal"] = value

    @property
    def injuries_incapacitating(self) -> float:
        return self._data.get("injuries_incapacitating")

    @injuries_incapacitating.setter
    def injuries_incapacitating(self, value: float):
        self._data["injuries_incapacitating"] = value

    @property
    def injuries_non_incapacitating(self) -> float:
        return self._data.get("injuries_non_incapacitating")

    @injuries_non_incapacitating.setter
    def injuries_non_incapacitating(self, value: float):
        self._data["injuries_non_incapacitating"] = value

    @property
    def injuries_reported_not_evident(self) -> float:
        return self._data.get("injuries_reported_not_evident")

    @injuries_reported_not_evident.setter
    def injuries_reported_not_evident(self, value: float):
        self._data["injuries_reported_not_evident"] = value

    @property
    def injuries_no_indication(self) -> float:
        return self._data.get("injuries_no_indication")

    @injuries_no_indication.setter
    def injuries_no_indication(self, value: float):
        self._data["injuries_no_indication"] = value

    @property
    def crash_hour(self) -> int:
        return self._data.get("crash_hour")

    @crash_hour.setter
    def crash_hour(self, value: int):
        self._data["crash_hour"] = value

    @property
    def crash_day_of_week(self) -> int:
        return self._data.get("crash_day_of_week")

    @crash_day_of_week.setter
    def crash_day_of_week(self, value: int):
        self._data["crash_day_of_week"] = value

    @property
    def crash_month(self) -> int:
        return self._data.get("crash_month")

    @crash_month.setter
    def crash_month(self, value: int):
        self._data["crash_month"] = value


# --- Classe DBManager (atualizada para interagir com o novo DataObject) ---
class DBManager:
    """
    Gerencia o banco de dados de arquivo plano e seu índice.
    """
    def __init__(self, db_file: Path, index_file: Path, id_counter_file: Path, lock_file: Path, logger: logging.Logger):
        self.db_file = db_file
        self.index_file = index_file
        self.id_counter_file = id_counter_file
        self.lock_file = filelock.FileLock(str(lock_file))
        self.logger = logger
        self._next_id = self._load_next_id()
        self._initialize_files()

    def _initialize_files(self):
        """Garante que os arquivos do banco de dados e do índice existam."""
        self.db_file.parent.mkdir(parents=True, exist_ok=True)
        self.db_file.touch(exist_ok=True)
        self.index_file.touch(exist_ok=True)

    def _load_next_id(self) -> int:
        """Carrega o próximo ID disponível de um arquivo contador."""
        try:
            if self.id_counter_file.exists():
                with self.id_counter_file.open('r') as f:
                    content = f.read().strip()
                    if content.isdigit():
                        return int(content)
            return 1
        except Exception as e:
            self.logger.error(f"Falha ao carregar o próximo ID de {self.id_counter_file}: {e}")
            return 1

    def _save_next_id(self):
        """Salva o próximo ID atual no arquivo contador."""
        try:
            with self.id_counter_file.open('w') as f:
                f.write(str(self._next_id))
        except Exception as e:
            self.logger.error(f"Falha ao salvar o próximo ID em {self.id_counter_file}: {e}")

    def _get_current_index(self) -> Dict[int, Dict[str, int]]:
        """Carrega o índice inteiro do arquivo."""
        index = {}
        try:
            if self.index_file.exists() and self.index_file.stat().st_size > 0:
                with self.index_file.open('r') as f:
                    index_data = json.load(f)
                    index = {int(k): v for k, v in index_data.items()}
        except json.JSONDecodeError as e:
            self.logger.error(f"Erro ao decodificar o arquivo de índice {self.index_file}: {e}. O índice será reconstruído se necessário.")
            # Opcionalmente, tenta reconstruir o índice aqui se corrompido
        except Exception as e:
            self.logger.error(f"Erro ao carregar o arquivo de índice {self.index_file}: {e}")
        return index

    def _save_index(self, index: Dict[int, Dict[str, int]]):
        """Salva o índice inteiro no arquivo."""
        try:
            with self.index_file.open('w') as f:
                json.dump(index, f, indent=4)
        except Exception as e:
            self.logger.error(f"Erro ao salvar o arquivo de índice {self.index_file}: {e}")

    def _append_record_to_db_file(self, record: DataObject) -> Tuple[int, int]:
        """Anexa um registro ao arquivo do banco de dados e retorna seu offset e tamanho."""
        data_json = json.dumps(record.to_dict(), ensure_ascii=False) + '\n'
        data_bytes = data_json.encode('utf-8')

        with self.db_file.open('ab') as f:
            offset = f.tell()
            f.write(data_bytes)
            size = len(data_bytes)
        return offset, size

    def _read_record_from_db_file(self, offset: int, size: int) -> Optional[DataObject]:
        """Lê um registro do arquivo do banco de dados dado seu offset e tamanho."""
        try:
            with self.db_file.open('rb') as f:
                f.seek(offset)
                data_bytes = f.read(size)
                data_json = data_bytes.decode('utf-8').strip()
                return DataObject(json.loads(data_json))
        except (IOError, json.JSONDecodeError, UnicodeDecodeError) as e:
            self.logger.error(f"Erro ao ler registro do DB no offset {offset}, tamanho {size}: {e}")
            return None

    def add_record(self, record_data: Dict[str, Any]) -> Optional[DataObject]:
        """Adiciona um novo registro ao banco de dados."""
        with self.lock_file:
            record = DataObject(record_data)
            record.id_registro = self._next_id # Alterado de record.id

            offset, size = self._append_record_to_db_file(record)

            index = self._get_current_index()
            index[record.id_registro] = {"offset": offset, "size": size, "deleted": 0} # Alterado de record.id
            self._save_index(index)

            self._next_id += 1
            self._save_next_id()
            self.logger.info(f"Registro adicionado: ID {record.id_registro}") # Alterado de record.id
            return record

    def get_record(self, record_id: int) -> Optional[DataObject]:
        """Recupera um registro pelo seu ID."""
        with self.lock_file:
            index = self._get_current_index()
            record_info = index.get(record_id)
            if record_info and record_info["deleted"] == 0:
                return self._read_record_from_db_file(record_info["offset"], record_info["size"])
            return None

    def update_record(self, record_id: int, new_data: Dict[str, Any]) -> Optional[DataObject]:
        """Atualiza um registro existente, marcando o antigo como excluído e adicionando o novo."""
        with self.lock_file:
            index = self._get_current_index()
            record_info = index.get(record_id)
            if not record_info or record_info["deleted"] == 1:
                self.logger.warning(f"Falha na atualização: Registro ID {record_id} não encontrado ou marcado para exclusão.")
                return None

            # Marca o registro antigo como excluído no índice
            record_info["deleted"] = 1

            # Adiciona a nova versão do registro
            updated_record = DataObject(new_data)
            updated_record.id_registro = record_id # Mantém o mesmo ID, alterado de .id

            offset, size = self._append_record_to_db_file(updated_record)

            index[record_id] = {"offset": offset, "size": size, "deleted": 0} # Nova entrada para o registro atualizado
            self._save_index(index)
            self.logger.info(f"Registro atualizado: ID {record_id}")
            return updated_record

    def delete_record(self, record_id: int) -> bool:
        """Marca um registro como excluído no índice."""
        with self.lock_file:
            index = self._get_current_index()
            if record_id in index:
                index[record_id]["deleted"] = 1
                self._save_index(index)
                self.logger.info(f"Registro marcado para exclusão: ID {record_id}")
                return True
            self.logger.warning(f"Falha na exclusão: Registro ID {record_id} não encontrado.")
            return False

    def list_all_records(self) -> List[DataObject]:
        """Lista todos os registros não excluídos."""
        records = []
        with self.lock_file:
            index = self._get_current_index()
            for record_id, record_info in index.items():
                if record_info["deleted"] == 0:
                    record = self._read_record_from_db_file(record_info["offset"], record_info["size"])
                    if record: # Garante que o registro foi lido com sucesso
                        records.append(record)
        return records

    def search_records(self, field: str, query: Any) -> List[DataObject]:
        """Busca registros com base em um campo e uma consulta."""
        results = []
        all_records = self.list_all_records() # Busca apenas em registros não excluídos
        for record in all_records:
            record_dict = record.to_dict()
            if field in record_dict:
                # Comparação básica de string (não sensível a maiúsculas/minúsculas para strings)
                if isinstance(record_dict[field], str) and isinstance(query, str):
                    if query.lower() in record_dict[field].lower():
                        results.append(record)
                # Para tipos de lista, verifica se algum elemento corresponde (não sensível a maiúsculas/minúsculas para strings na lista)
                elif isinstance(record_dict[field], list) and isinstance(query, str):
                    if any(query.lower() in str(item).lower() for item in record_dict[field]):
                        results.append(record)
                elif record_dict[field] == query:
                    results.append(record)
        return results

    def compact_db(self):
        """
        Reescreve o arquivo do banco de dados, removendo registros excluídos e atualizando o índice.
        Esta é uma operação que exige muito desempenho.
        """
        self.logger.info("Iniciando compactação do banco de dados...")
        st.info("Iniciando compactação do banco de dados... Isso pode levar um tempo.")
        temp_db_file = self.db_file.with_suffix('.db.tmp')
        new_index = {}
        try:
            with self.lock_file:
                current_index = self._get_current_index()
                with temp_db_file.open('wb') as temp_f:
                    for record_id in sorted(current_index.keys()):
                        record_info = current_index[record_id]
                        if record_info["deleted"] == 0:
                            record = self._read_record_from_db_file(record_info["offset"], record_info["size"])
                            if record:
                                data_json = json.dumps(record.to_dict(), ensure_ascii=False) + '\n'
                                data_bytes = data_json.encode('utf-8')

                                offset = temp_f.tell()
                                temp_f.write(data_bytes)
                                size = len(data_bytes)
                                new_index[record.id_registro] = {"offset": offset, "size": size, "deleted": 0} # Alterado de .id

                # Substitui o arquivo DB antigo pelo novo
                shutil.replace(temp_db_file, self.db_file)
                self._save_index(new_index)
                self.logger.info("Compactação do banco de dados concluída com sucesso.")
                st.success("Compactação do banco de dados concluída com sucesso!")
        except Exception as e:
            self.logger.error(f"Erro durante a compactação do banco de dados: {traceback.format_exc()}")
            st.error(f"🚨 Erro durante a compactação do banco de dados: {e}")
        finally:
            if temp_db_file.exists():
                temp_db_file.unlink() # Limpa o arquivo temporário


# Placeholder para BTreeDBManager (assumindo que também precisa interagir com DataObject)
# Para o propósito desta refatoração, assumiremos que seus pontos de interação
# com DataObject (como add_record, get_record, etc.) seriam atualizados de forma semelhante
# ao DBManager.
class BTreeDBManager:
    def __init__(self, db_file: Path, btree_index_file: Path, id_counter_file: Path, lock_file: Path, logger: logging.Logger, page_size: int, min_degree: int):
        self.db_file = db_file
        self.btree_index_file = btree_index_file
        self.id_counter_file = id_counter_file
        self.lock_file = filelock.FileLock(str(lock_file))
        self.logger = logger
        self.page_size = page_size
        self.min_degree = min_degree
        self._next_id = self._load_next_id()
        self._initialize_files()
        # Placeholder para a implementação real da B-Tree
        self.b_tree = None # Esta seria uma instância de uma classe B-Tree

    def _initialize_files(self):
        self.db_file.parent.mkdir(parents=True, exist_ok=True)
        self.db_file.touch(exist_ok=True)
        self.btree_index_file.touch(exist_ok=True)

    def _load_next_id(self) -> int:
        try:
            if self.id_counter_file.exists():
                with self.id_counter_file.open('r') as f:
                    content = f.read().strip()
                    if content.isdigit():
                        return int(content)
            return 1
        except Exception as e:
            self.logger.error(f"Falha ao carregar o próximo ID de {self.id_counter_file}: {e}")
            return 1

    def _save_next_id(self):
        try:
            with self.id_counter_file.open('w') as f:
                f.write(str(self._next_id))
        except Exception as e:
            self.logger.error(f"Falha ao salvar o próximo ID em {self.id_counter_file}: {e}")

    def _append_record_to_db_file(self, record: DataObject) -> Tuple[int, int]:
        """Anexa um registro ao arquivo do banco de dados e retorna seu offset e tamanho."""
        data_json = json.dumps(record.to_dict(), ensure_ascii=False) + '\n'
        data_bytes = data_json.encode('utf-8')

        with self.db_file.open('ab') as f:
            offset = f.tell()
            f.write(data_bytes)
            size = len(data_bytes)
        return offset, size

    def _read_record_from_db_file(self, offset: int, size: int) -> Optional[DataObject]:
        """Lê um registro do arquivo do banco de dados dado seu offset e tamanho."""
        try:
            with self.db_file.open('rb') as f:
                f.seek(offset)
                data_bytes = f.read(size)
                data_json = data_bytes.decode('utf-8').strip()
                return DataObject(json.loads(data_json))
        except (IOError, json.JSONDecodeError, UnicodeDecodeError) as e:
            self.logger.error(f"Erro ao ler registro do DB no offset {offset}, tamanho {size}: {e}")
            return None

    def add_record(self, record_data: Dict[str, Any]) -> Optional[DataObject]:
        with self.lock_file:
            record = DataObject(record_data)
            record.id_registro = self._next_id # Alterado de record.id
            offset, size = self._append_record_to_db_file(record)
            # Em uma B-Tree real, você inseriria a chave (id_registro) e o valor (offset, size)
            # self.b_tree.insert(record.id_registro, {"offset": offset, "size": size})
            self._next_id += 1
            self._save_next_id()
            self.logger.info(f"Registro adicionado ao DB B-Tree: ID {record.id_registro}") # Alterado de record.id
            return record

    def get_record(self, record_id: int) -> Optional[DataObject]:
        with self.lock_file:
            # Em uma B-Tree real, você buscaria o record_id
            # record_info = self.b_tree.search(record_id)
            # if record_info and not record_info.get("deleted", 0):
            #    return self._read_record_from_db_file(record_info["offset"], record_info["size"])
            self.logger.warning(f"BTreeDBManager: get_record não totalmente implementado para ID {record_id}")
            return None

    def update_record(self, record_id: int, new_data: Dict[str, Any]) -> Optional[DataObject]:
        with self.lock_file:
            # Em uma B-Tree real, você encontraria o registro antigo, o marcaria para exclusão/atualização,
            # e então inseriria o novo registro.
            # self.b_tree.delete(record_id) # Marca o antigo como excluído ou substitui
            updated_record = DataObject(new_data)
            updated_record.id_registro = record_id # Alterado de .id
            offset, size = self._append_record_to_db_file(updated_record)
            # self.b_tree.insert(record_id, {"offset": offset, "size": size})
            self.logger.info(f"Registro atualizado no DB B-Tree: ID {record_id}")
            return updated_record

    def delete_record(self, record_id: int) -> bool:
        with self.lock_file:
            # self.b_tree.delete(record_id) # Marca como excluído na B-Tree
            self.logger.info(f"Registro marcado para exclusão no DB B-Tree: ID {record_id}")
            return True

    def list_all_records(self) -> List[DataObject]:
        records = []
        with self.lock_file:
            self.logger.warning("BTreeDBManager: list_all_records não totalmente implementado.")
            # Isso normalmente envolveria a travessia da B-Tree
        return records

    def search_records(self, field: str, query: Any) -> List[DataObject]:
        results = []
        self.logger.warning("BTreeDBManager: search_records não totalmente implementado.")
        # Para uma B-Tree, a busca por campos não-chave ainda provavelmente envolveria
        # iterar por todos os registros ou manter índices secundários.
        return self.list_all_records() # Retorno para varredura completa se não houver lógica de busca B-Tree


# --- Classe CryptoHandler (de pycryptonew.py, integrada) ---
class CryptoHandler:
    def __init__(self, public_key_path: Path, private_key_path: Path, logger: logging.Logger):
        self.public_key_path = public_key_path
        self.private_key_path = private_key_path
        self.logger = logger

    def generate_rsa_key_pair(self, password: Optional[str] = None):
        if self.public_key_path.exists() and self.private_key_path.exists():
            self.logger.info("O par de chaves RSA já existe.")
            return

        try:
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            public_key = private_key.public_key()

            # Serializa a chave privada
            encryption_algorithm = serialization.NoEncryption()
            if password:
                encryption_algorithm = serialization.BestAvailableEncryption(password.encode('utf-8'))

            with self.private_key_path.open("wb") as f:
                f.write(private_key.private_bytes(
                    encoding=serialization.Encoding.PEM,
                    format=serialization.PrivateFormat.PKCS8,
                    encryption_algorithm=encryption_algorithm
                ))

            # Serializa a chave pública
            with self.public_key_path.open("wb") as f:
                f.write(public_key.public_bytes(
                    encoding=serialization.Encoding.PEM,
                    format=serialization.PublicFormat.SubjectPublicKeyInfo
                ))
            self.logger.info("Par de chaves RSA gerado e salvo.")
            st.success("Par de chaves RSA gerado com sucesso!")
        except Exception as e:
            self.logger.error(f"Erro ao gerar par de chaves RSA: {traceback.format_exc()}")
            st.error(f"🚨 Erro ao gerar par de chaves RSA: {e}")

    def load_public_key(self):
        try:
            with self.public_key_path.open("rb") as f:
                public_key = serialization.load_pem_public_key(f.read(), backend=default_backend())
            return public_key
        except Exception as e:
            self.logger.error(f"Erro ao carregar chave pública: {traceback.format_exc()}")
            return None

    def load_private_key(self, password: Optional[str] = None):
        try:
            with self.private_key_path.open("rb") as f:
                private_key = serialization.load_pem_private_key(
                    f.read(),
                    password=password.encode('utf-8') if password else None,
                    backend=default_backend()
                )
            return private_key
        except Exception as e:
            self.logger.error(f"Erro ao carregar chave privada: {traceback.format_exc()}")
            st.error(f"🚨 Erro ao carregar chave privada. Verifique a senha. Erro: {e}")
            return None

    def encrypt_aes_key_with_rsa(self, aes_key: bytes, public_key) -> bytes:
        return public_key.encrypt(
            aes_key,
            padding.OAEP(
                mgf=padding.MGF1(algorithm=hashes.SHA256()),
                algorithm=hashes.SHA256(),
                label=None
            )
        )

    def decrypt_aes_key_with_rsa(self, encrypted_aes_key: bytes, private_key) -> bytes:
        return private_key.decrypt(
            encrypted_aes_key,
            padding.OAEP(
                mgf=padding.MGF1(algorithm=hashes.SHA256()),
                algorithm=hashes.SHA256(),
                label=None
            )
        )

    def encrypt_data(self, data: bytes, public_key) -> Tuple[bytes, bytes]:
        aes_key = os.urandom(32)  # Chave AES de 256 bits
        iv = os.urandom(16)  # IV de 128 bits
        cipher = Cipher(algorithms.AES(aes_key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data) + encryptor.finalize()
        encrypted_aes_key = self.encrypt_aes_key_with_rsa(aes_key, public_key)
        return encrypted_data, iv + encrypted_aes_key # Combina IV e chave AES criptografada para armazenamento

    def decrypt_data(self, encrypted_data_with_iv_and_key: bytes, private_key) -> bytes:
        iv_len = 16
        # A parte `encrypted_data = encrypted_data_with_iv_and_key[iv_len + len(encrypted_aes_key):]`
        # é complicada, precisa garantir o fatiamento correto.

        # Re-calcula encrypted_data com base nos dados reais
        # Para simplificar, assume que encrypted_data é o restante após IV e encrypted_aes_key
        # Uma abordagem melhor é armazenar os comprimentos explicitamente ou usar um formato estruturado
        # Por enquanto, usaremos apenas os `encrypted_data` passados se estiverem separados,
        # ou os derivaremos corretamente do blob combinado.

        # REVISANDO: A função `encrypt_data` retorna `encrypted_data, iv + encrypted_aes_key`.
        # Portanto, `decrypt_data` precisaria de `encrypted_data` e `iv + encrypted_aes_key` passados separadamente.
        # Ou, o retorno de `encrypt_data` deveria ser um único blob: `iv + encrypted_aes_key + actual_encrypted_data`.

        # Vamos assumir que `encrypted_data_with_iv_and_key` é o resultado de
        # `iv + encrypted_aes_key + actual_encrypted_data`.
        rsa_key_size_bytes = 2048 // 8 # Para chave RSA de 2048 bits
        encrypted_aes_key_len = rsa_key_size_bytes # O tamanho da saída da criptografia RSA é igual ao tamanho da chave

        if len(encrypted_data_with_iv_and_key) < iv_len + encrypted_aes_key_len:
            self.logger.error("Comprimento inválido do blob de dados criptografados para descriptografia.")
            return b""

        iv = encrypted_data_with_iv_and_key[:iv_len]
        encrypted_aes_key = encrypted_data_with_iv_and_key[iv_len : iv_len + encrypted_aes_key_len]
        actual_encrypted_data = encrypted_data_with_iv_and_key[iv_len + encrypted_aes_key_len:]

        try:
            aes_key = self.decrypt_aes_key_with_rsa(encrypted_aes_key, private_key)
            cipher = Cipher(algorithms.AES(aes_key), modes.CFB(iv), backend=default_backend())
            decryptor = cipher.decryptor()
            decrypted_data = decryptor.update(actual_encrypted_data) + decryptor.finalize()
            return decrypted_data
        except Exception as e:
            self.logger.error(f"Erro ao descriptografar dados: {traceback.format_exc()}")
            st.error(f"🚨 Erro ao descriptografar dados. Verifique a chave ou o formato. Erro: {e}")
            return b""

# --- Manipuladores de Compressão (Placeholders) ---
class HuffmanCompression:
    def compress(self, data: bytes) -> bytes:
        # Placeholder para a lógica de compressão Huffman
        self.logger.info("Realizando compressão Huffman (placeholder).")
        return data # Retorna os dados originais por enquanto

    def decompress(self, data: bytes) -> bytes:
        # Placeholder para a lógica de descompressão Huffman
        self.logger.info("Realizando descompressão Huffman (placeholder).")
        return data # Retorna os dados originais por enquanto

class LZWCompression:
    def compress(self, data: bytes) -> bytes:
        # Placeholder para a lógica de compressão LZW
        self.logger.info("Realizando compressão LZW (placeholder).")
        return data # Retorna os dados originais por enquanto

    def decompress(self, data: bytes) -> bytes:
        # Placeholder para a lógica de descompressão LZW
        self.logger.info("Realizando descompressão LZW (placeholder).")
        return data # Retorna os dados originais por enquanto

# --- Configuração da UI do Streamlit ---
# Esta parte é ilustrativa e precisaria de uma refatoração mais detalhada
# com base no código real da UI do Streamlit no stInsertDataObjectPY.py original.
# A função `setup_ui` do código original não é fornecida, então esta é uma adaptação geral.

# Função placeholder para configuração da UI do Streamlit
def setup_ui():
    st.set_page_config(layout="wide", page_title="Gerenciador de Acidentes de Trânsito")
    st.title("Sistema de Gerenciamento de Acidentes de Trânsito")

    # Inicializa CryptoHandler
    crypto_handler = CryptoHandler(RSA_PUBLIC_KEY_PATH, RSA_PRIVATE_KEY_PATH, logger)

    # Seção de Geração de Chaves
    with st.expander("Gerar Chaves RSA"):
        st.write("Gere um novo par de chaves RSA para criptografia e descriptografia.")
        password = st.text_input("Senha para a chave privada (opcional):", type="password", key="rsa_pass_gen")
        if st.button("Gerar Chaves RSA"):
            crypto_handler.generate_rsa_key_pair(password)
            st.session_state.rsa_keys_generated = True

    # Seleção do Tipo de Banco de Dados
    db_type_selection = st.radio("Selecione o tipo de banco de dados:", ("Flat-file (Padrão)", "B-Tree (Experimental)"), key="db_type_radio")
    if db_type_selection == "Flat-file (Padrão)":
        st.session_state.db_type = "default"
        st.session_state.db = DBManager(DB_FILE_PATH, INDEX_FILE_PATH, ID_COUNTER_PATH, LOCK_FILE_PATH, logger)
    else:
        st.session_state.db_type = "btree"
        st.session_state.db = BTreeDBManager(DB_FILE_PATH, BTREE_INDEX_FILE_PATH, ID_COUNTER_PATH, LOCK_FILE_PATH, logger, APP_CONFIG["BTREE_PAGE_SIZE"], APP_CONFIG["BTREE_MIN_DEGREE"])

    db_manager = st.session_state.db # Usa o gerenciador de DB selecionado

    # Operações CRUD
    st.header("Operações de Registro de Acidentes")

    # Formulário para adicionar/atualizar registros
    with st.form("accident_form", clear_on_submit=True):
        st.subheader("Inserir/Atualizar Registro")
        record_id_input = st.number_input("ID do Registro (para atualização, 0 para novo):", min_value=0, value=0, step=1, key="record_id_input")

        # Campos de entrada para os novos atributos do DataObject
        crash_date = st.text_input("Data do Acidente (YYYY-MM-DD HH:MM:SS):", help="Ex: 2023-10-27 14:30:00", key="crash_date")
        data_local = st.text_input("Data Local (YYYY-MM-DD):", help="Ex: 2023-10-27", key="data_local")
        traffic_control_device = st.text_input("Dispositivo de Controle de Tráfego:", key="traffic_control_device")
        weather_condition = st.text_input("Condição Climática:", key="weather_condition")
        lighting_condition = st.text_input("Condição de Iluminação (separar por vírgula):", key="lighting_condition")
        first_crash_type = st.text_input("Tipo do Primeiro Acidente:", key="first_crash_type")
        trafficway_type = st.text_input("Tipo de Via:", key="trafficway_type")
        alignment = st.text_input("Alinhamento:", key="alignment")
        roadway_surface_cond = st.text_input("Condição da Superfície da Via:", key="roadway_surface_cond")
        road_defect = st.text_input("Defeito na Via:", key="road_defect")
        crash_type = st.text_input("Tipo de Acidente (separar por vírgula):", key="crash_type_input")
        intersection_related_i = st.checkbox("Relacionado a Interseção?", key="intersection_related_i")
        damage = st.text_input("Danos:", key="damage")
        prim_contributory_cause = st.text_input("Causa Contribuinte Primária:", key="prim_contributory_cause")
        num_units = st.number_input("Número de Unidades Envolvidas:", min_value=0, step=1, key="num_units")
        most_severe_injury = st.text_input("Lesão Mais Grave (separar por vírgula):", key="most_severe_injury")
        injuries_total = st.number_input("Total de Feridos:", min_value=0.0, step=0.1, key="injuries_total")
        injuries_fatal = st.number_input("Feridos Fatais:", min_value=0.0, step=0.1, key="injuries_fatal")
        injuries_incapacitating = st.number_input("Feridos Incapacitantes:", min_value=0.0, step=0.1, key="injuries_incapacitating")
        injuries_non_incapacitating = st.number_input("Feridos Não Incapacitantes:", min_value=0.0, step=0.1, key="injuries_non_incapacitating")
        injuries_reported_not_evident = st.number_input("Feridos Reportados (Não Evidentes):", min_value=0.0, step=0.1, key="injuries_reported_not_evident")
        injuries_no_indication = st.number_input("Feridos Sem Indicação:", min_value=0.0, step=0.1, key="injuries_no_indication")
        crash_hour = st.number_input("Hora do Acidente (0-23):", min_value=0, max_value=23, step=1, key="crash_hour")
        crash_day_of_week = st.number_input("Dia da Semana do Acidente (1=Dom, 7=Sáb):", min_value=1, max_value=7, step=1, key="crash_day_of_week")
        crash_month = st.number_input("Mês do Acidente (1-12):", min_value=1, max_value=12, step=1, key="crash_month")


        submitted = st.form_submit_button("Salvar Registro")

        if submitted:
            record_data = {
                "id_registro": record_id_input,
                "crash_date": crash_date,
                "data_local": data_local,
                "traffic_control_device": traffic_control_device,
                "weather_condition": weather_condition,
                "lighting_condition": lighting_condition, # DataObject irá lidar com a divisão
                "first_crash_type": first_crash_type,
                "trafficway_type": trafficway_type,
                "alignment": alignment,
                "roadway_surface_cond": roadway_surface_cond,
                "road_defect": road_defect,
                "crash_type": crash_type, # DataObject irá lidar com a divisão
                "intersection_related_i": intersection_related_i,
                "damage": damage,
                "prim_contributory_cause": prim_contributory_cause,
                "num_units": num_units,
                "most_severe_injury": most_severe_injury, # DataObject irá lidar com a divisão
                "injuries_total": injuries_total,
                "injuries_fatal": injuries_fatal,
                "injuries_incapacitating": injuries_incapacitating,
                "injuries_non_incapacitating": injuries_non_incapacitating,
                "injuries_reported_not_evident": injuries_reported_not_evident,
                "injuries_no_indication": injuries_no_indication,
                "crash_hour": crash_hour,
                "crash_day_of_week": crash_day_of_week,
                "crash_month": crash_month,
            }

            if record_id_input == 0:
                new_record = db_manager.add_record(record_data)
                if new_record:
                    st.success(f"Registro adicionado com sucesso! ID: {new_record.id_registro}")
            else:
                updated_record = db_manager.update_record(record_id_input, record_data)
                if updated_record:
                    st.success(f"Registro ID {updated_record.id_registro} atualizado com sucesso!")
                else:
                    st.error(f"Não foi possível atualizar o registro ID {record_id_input}.")

    # Visualizar registros
    st.subheader("Visualizar Registros")
    if st.button("Listar Todos os Registros"):
        records = db_manager.list_all_records()
        if records:
            st.dataframe([r.to_dict() for r in records])
        else:
            st.info("Nenhum registro encontrado.")

    # Buscar registros
    st.subheader("Buscar Registros")
    search_field = st.selectbox("Buscar por campo:", list(DataObject({}).to_dict().keys()), key="search_field_select") # Obtém campos dinamicamente
    search_query = st.text_input(f"Valor para buscar em '{search_field}':", key="search_query_input")
    if st.button("Buscar"):
        # O método search_records precisa lidar com os novos nomes de campo e, potencialmente, comparações de lista.
        # O search_records existente no DBManager já lida com comparação de string não sensível a maiúsculas/minúsculas e igualdade direta.
        # Para campos de lista, a lógica existente verifica se 'query' é uma subcadeia de qualquer item na lista (após converter o item da lista em string).
        # Essa abordagem deve funcionar geralmente para os novos campos de lista também, desde que a consulta seja uma string.

        # No entanto, para campos booleanos como 'intersection_related_i', a comparação direta de strings pode não funcionar como esperado.
        # Vamos garantir que o método search_records lide com a conversão booleana para a consulta se o campo for booleano.

        # Para demonstração, vamos manter o `search_records` existente que faz um bom trabalho
        # para comparações de string e valor direto. Para busca baseada em lista, ele converterá elementos da lista
        # para string e verificará por subcadeia, o que é razoável.

        # Tratamento especial para campo booleano:
        if search_field == "intersection_related_i":
            if search_query.lower() in ["true", "s", "sim", "yes", "verdadeiro"]:
                actual_query = True
            elif search_query.lower() in ["false", "n", "não", "no", "falso"]:
                actual_query = False
            else:
                st.warning("Para 'Relacionado a Interseção', use 'True' ou 'False'.")
                actual_query = None # Resultará em nenhuma correspondência se None

            if actual_query is not None:
                found_records = db_manager.search_records(search_field, actual_query)
        else:
            found_records = db_manager.search_records(search_field, search_query)

        if found_records:
            st.dataframe([r.to_dict() for r in found_records])
        else:
            st.info("Nenhum registro encontrado com os critérios de busca.")


    # Excluir registro
    st.subheader("Excluir Registro")
    delete_id = st.number_input("ID do Registro para excluir:", min_value=0, step=1, key="delete_id_input")
    if st.button("Excluir Registro"):
        if db_manager.delete_record(delete_id):
            st.success(f"Registro ID {delete_id} excluído com sucesso.")
        else:
            st.error(f"Não foi possível excluir o registro ID {delete_id}.")

    # Compactação do banco de dados
    st.subheader("Compactação do Banco de Dados")
    if st.button("Compactar Banco de Dados (Remover Registros Excluídos)"):
        db_manager.compact_db()

    # Seção de Criptografia/Descriptografia (placeholder para integração)
    st.header("Criptografia e Descriptografia de Banco de Dados")
    st.info("Funcionalidades de criptografia e descriptografia serão integradas aqui.")
    # Esta seção exigiria mudanças significativas no DBManager e BTreeDBManager
    # para lidar com a leitura/escrita de conteúdo criptografado, e integração com CryptoHandler.
    # Para esta refatoração, manteremos os elementos da UI como placeholders.

    # Seção de Compressão (placeholder para integração)
    st.header("Compressão e Descompressão de Banco de Dados")
    st.info("Funcionalidades de compressão e descompressão (LZW, Huffman) serão integradas aqui.")
    # Semelhante à criptografia, isso exigiria mudanças no DBManager/BTreeDBManager
    # para interagir com HuffmanCompression e LZWCompression.

    st.markdown("""
    ---
    ### Sobre o Aplicativo
    Este aplicativo gerencia um banco de dados de acidentes de trânsito.

    **Funcionalidades:**
    - Gerenciamento de registros CRUD (Criar, Ler, Atualizar, Excluir).
    - Suporte a banco de dados flat-file e experimentalmente a B-Tree.
    - Geração e gerenciamento de chaves RSA para criptografia.
    - Placeholder para compressão e descompressão de arquivos (LZW e Huffman).
    - Criptografia e descriptografia híbrida (AES com chave RSA).
    - Geração e gerenciamento de chaves RSA.
    - Registro de atividades do sistema.

    **Desenvolvido por:** [Seu Nome/Organização]
    **Versão:** 1.0 Alpha

    **Tecnologias Utilizadas:**
    - Python
    - Streamlit
    - `pathlib`
    - `filelock`
    - `cryptography` (para AES/RSA)
    - `csv`
    - `json`

    Agradecemos por usar este aplicativo!
    """)

# --- Ponto de Entrada Principal da Aplicação ---
if __name__ == "__main__":
    try:
        # Garante que os diretórios base existam
        APP_CONFIG["DB_DIR"].mkdir(parents=True, exist_ok=True)
        BACKUP_PATH.mkdir(parents=True, exist_ok=True)
        APP_CONFIG["RSA_KEYS_DIR"].mkdir(parents=True, exist_ok=True)
        HUFFMAN_FOLDER.mkdir(parents=True, exist_ok=True)
        LZW_FOLDER.mkdir(parents=True, exist_ok=True)

        setup_ui()
    except OSError as e:
        st.error(f"🚨 Crítico: Não foi possível criar os diretórios necessários. Verifique as permissões para `{APP_CONFIG['DB_DIR']}`. Erro: {e}")
        logger.critical(f"Falha na criação inicial do diretório: {traceback.format_exc()}")
        st.stop() # Interrompe o aplicativo se os diretórios não puderem ser criados.

"""<div class="md-recitation">
  Sources
  <ol>
  <li><a href="https://blog.csdn.net/universsky2015/article/details/136012807">https://blog.csdn.net/universsky2015/article/details/136012807</a></li>
  <li><a href="https://cloud.tencent.com/developer/article/2186122">https://cloud.tencent.com/developer/article/2186122</a></li>
  <li><a href="https://bbs.huaweicloud.com/blogs/104554">https://bbs.huaweicloud.com/blogs/104554</a></li>
  <li><a href="https://github.com/techmovie/notion-telegram-bot">https://github.com/techmovie/notion-telegram-bot</a></li>
  <li><a href="https://mliew2.github.io/424/">https://mliew2.github.io/424/</a></li>
  <li><a href="https://github.com/SagarGyawali-glitch/JWKS-server">https://github.com/SagarGyawali-glitch/JWKS-server</a></li>
  <li><a href="https://planet.sito.ir/%D8%B1%D9%85%D8%B2%D9%86%DA%AF%D8%A7%D8%B1%DB%8C-%D9%88-%D8%B1%D9%85%D8%B2%DA%AF%D8%B4%D8%A7%DB%8C%DB%8C-%D8%A8%D9%87-%D8%B4%DB%8C%D9%88%D9%87-%D9%86%D8%A7%D9%85%D8%AA%D9%82%D8%A7%D8%B1%D9%86-%D8%AF/">https://planet.sito.ir/%D8%B1%D9%85%D8%B2%D9%86%DA%AF%D8%A7%D8%B1%DB%8C-%D9%88-%D8%B1%D9%85%D8%B2%DA%AF%D8%B4%D8%A7%DB%8C%DB%8C-%D8%A8%D9%87-%D8%B4%DB%8C%D9%88%D9%87-%D9%86%D8%A7%D9%85%D8%AA%D9%82%D8%A7%D8%B1%D9%86-%D8%AF/</a></li>
  <li><a href="https://gist.github.com/artizirk/538619d4a654ada9a01f3bd1670a6fa6">https://gist.github.com/artizirk/538619d4a654ada9a01f3bd1670a6fa6</a></li>
  <li><a href="https://github.com/NaeuralEdgeProtocol/PyE2">https://github.com/NaeuralEdgeProtocol/PyE2</a></li>
  <li><a href="https://juejin.cn/post/7202399271574831161">https://juejin.cn/post/7202399271574831161</a></li>
  <li><a href="https://github.com/andrewgodwin/takahe">https://github.com/andrewgodwin/takahe</a></li>
  <li><a href="https://github.com/Apocellipse/BTP">https://github.com/Apocellipse/BTP</a></li>
  <li><a href="https://github.com/FabienRoger/keyloger">https://github.com/FabienRoger/keyloger</a></li>
  <li><a href="https://github.com/Aarav2402/SecureOnlineAssessment">https://github.com/Aarav2402/SecureOnlineAssessment</a></li>
  <li><a href="https://github.com/Dipesh412/VirtuCryptMigrate">https://github.com/Dipesh412/VirtuCryptMigrate</a></li>
  <li><a href="https://github.com/JLdiablol/Scripts">https://github.com/JLdiablol/Scripts</a></li>
  <li><a href="https://github.com/ndarwich/Crash-Analysis">https://github.com/ndarwich/Crash-Analysis</a></li>
  </ol>
</div>
"""